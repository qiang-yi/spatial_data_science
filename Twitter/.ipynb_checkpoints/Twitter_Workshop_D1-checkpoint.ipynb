{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spatial Data Science (GIS6307/GEO4930)\n",
    "\n",
    "\n",
    "<br>\n",
    "Instructor: Yi Qiang (qiangy@usf.edu)<br>\n",
    "Teaching Assistant: Jinwen Xu (jinwenxu@usf.edu)\n",
    "\n",
    "---\n",
    "\n",
    "# Workshop on Spatial Analysis of Twitter (Day 1)\n",
    "\n",
    "This workshop will help you to get started with the acquisition, processing, and analysis of Twitter data using data science techniques. Specifically, you will learn:\n",
    "\n",
    "- Streaming real-time tweets using Twitter Developer APIs.\n",
    "- Processing the raw tweets into an analyzable form.\n",
    "- Basic mapping, spatial analysis and natural language processing for Twitter data.\n",
    "\n",
    "### Prerequisites\n",
    "- Install Anaconda in your computer.\n",
    "- Activation of Twitter Developer Account and approved **Elevated Access** before the workshop.\n",
    "- Basic programming skills are recommended, but not required.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Python Libraries\n",
    "\n",
    "First, we need to install a few libraries that will be used this lab. Please do the following steps to install the libarries.\n",
    "\n",
    "1. Open or create a new conda environment `geo`. \n",
    "- For students in courses GIS6307 and GEO4930, please open Anaconda Prompt, and use the command `conda activate geo` to activate the \"geo\" environment that you created in the previous lab. \n",
    "\n",
    "- For workshop participatns, please run the following code to create a new conda environment `geo` and then activate it.\n",
    "\n",
    "    - `conda create --name geo`\n",
    "    \n",
    "    - `conda activate geo`\n",
    "\n",
    "2. Install tweepy, folium and Jupyter Lab using the following command (GIS6307/GEO4930 students only need to install tweepy and folium):\n",
    "\n",
    "    `conda install -c conda-forge tweepy folium jupyterlab matplotlib emoji wordcloud textblob`\n",
    "    \n",
    "    \n",
    "3. Install pandas and nltk using the following command (GIS6307/GEO4930 students only need to install nltk):\n",
    "\n",
    "    `conda install -c anaconda pandas nltk`\n",
    "    \n",
    "\n",
    "4. Launch Jupyter Notebook using the following command:\n",
    "\n",
    "    `jupyter notebook`\n",
    "    \n",
    "\n",
    "5. Open the Twitter_Workshop_D1.ipynb that you just downloaded. Run the following code to import the installed libraries. If the code runs through, the libraries are installed successfully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import folium\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting to Know Jupyter Notebook\n",
    "\n",
    "Keyboard shortcuts will save you lots of time. Jupyter stores a list of keybord shortcuts under the menu at the top: Help > Keyboard Shortcuts, or by pressing `H` in command mode (more on that later). It’s worth checking this each time you update Jupyter, as more shortcuts are added all the time.\n",
    "\n",
    "Another way to access keyboard shortcuts, and a handy way to learn them is to use the command palette: `Cmd + Shift + P` (or `Ctrl + Shift + P` on Linux and Windows). This dialog box helps you run any command by name – useful if you don’t know the keyboard shortcut for an action or if what you want to do does not have a keyboard shortcut. The functionality is similar to Spotlight search on a Mac, and once you start using it you’ll wonder how you lived without it!\n",
    "\n",
    "Some of my favorite shortcuts (in command mode):\n",
    "\n",
    "- `ESC`: exit cell editing and enter to command mode\n",
    "- `A`: add a cell above the current cell\n",
    "- `B`: add a cell below the current cell\n",
    "- `C`: copy the current cell\n",
    "- `X`: cut the current cell\n",
    "- `V`: paste the copied cell below the current cell\n",
    "- `DD`: delete the current cell\n",
    "- `M`: change cell to MarkDown code (must exit editing first)\n",
    "- `Y`: change cell to Python code (must exit editing first)\n",
    "- `Ctrl + Enter`: Run code in the current cell.\n",
    "- `Shift + Enter`: Run code in the current cell and move to the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Set-Up Connection to Twitter\n",
    "\n",
    "Go to Twitter Developer Portal (https://developer.twitter.com/en/apps). Click the App you created in account activation.\n",
    "\n",
    "If you haven't created an App when you created the account, you can create one in the project.\n",
    "\n",
    "Click `Set up` to set up User authentification settings.\n",
    "\n",
    "![](https://raw.githubusercontent.com/qiang-yi/spatial_data_science/main/image/twitter/signup3.jpg)\n",
    "\n",
    "Turn on `OAuth 1.0a` and keep `OAuth 2.0` off. \n",
    "\n",
    "![](https://raw.githubusercontent.com/qiang-yi/spatial_data_science/main/image/twitter/OAuth.jpg)\n",
    "\n",
    "Select \"Read and write and Direct message\". You can use \"http://127.0.0.1:8080\" as Callback URL. Add any website as the website URL (e.g. your personal website or https://twitter.com).\n",
    "\n",
    "![](https://raw.githubusercontent.com/qiang-yi/spatial_data_science/main/image/twitter/setting.jpg)\n",
    "\n",
    "Copy the API keys you have saved when you activated your Developer account, and paste them to replace \"......\" below. If you can't find them, you can **regenerate** the keys and tokens in your Developer Portal. \n",
    "\n",
    "![](https://raw.githubusercontent.com/qiang-yi/spatial_data_science/main/image/twitter/keys2.jpg)\n",
    "\n",
    "Copy and paste your API key, API key secret, Access Token and Access Token Secret to replace \"......\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_key = '......'\n",
    "API_key_secret = '......'\n",
    "access_token = '......'\n",
    "access_token_secret = '......'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up for Twitter authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(API_key, API_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up tweepy API and set rate limit to be true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Simple Operation with Twitter APIs\n",
    "\n",
    "Now, your working environment is set up for Twitter analysis. Let's first try a few simple operations to acquire Twitter data in a programmatic way.\n",
    "\n",
    "The full functionalities of Twitter API and Tweepy can be found in:\n",
    "\n",
    "- [Twitter APIs](https://developer.twitter.com/en/docs.html)\n",
    "- [Tweepy documentation](http://docs.tweepy.org/en/v4.8.0/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Posting/Deleting a Tweet\n",
    "\n",
    "First, let's post a message in your Twitter account.\n",
    "\n",
    "**Note**: if you don't want to disturb your followers with a meanless tweet, don't run the following block of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post a tweet from Python\n",
    "test_tweet = api.update_status(\"DRILL: I'm creating a robot to tweet!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check your Twitter account, and you'll see the above message is posted.\n",
    "\n",
    "![](https://raw.githubusercontent.com/qiang-yi/spatial_data_science/main/image/twitter/tweet.jpg)\n",
    "\n",
    "Tweets are encoded in a JSON (JavaScript Object Notation) format. You can run the following code to check the content of the tweet you just posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet._json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`_json` returns a dictionary object. So you could access specific attributes using keys in the dictionary. The code below gets the posting time of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet._json['created_at']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative, you can also use the built-in attribute of the tweepy status object to access the attribute. All attributes of a tweet can be found [here](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_tweet.created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the following code to delete the drill tweet you just posted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api.destroy_status(test_tweet.id_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Getting Trending Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Twitter, you can find trends in different places in the Explore tab.\n",
    "\n",
    "![](https://raw.githubusercontent.com/qiang-yi/spatial_data_science/main/image/twitter/trends.jpg)\n",
    "\n",
    "Next, we are going to retrieve trends in Python. The following code get a list of places where trends are available. These places include countries and cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "place_ls = api.available_trends()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the list (in JSON format) into a dataframe (i.e. a table). Print the number of places where trends are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place = pd.DataFrame(place_ls)\n",
    "\n",
    "print (str(len(df_place)) + \" places have trends.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview 10 places where trends are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the record of Tampa. The `woeid` is a unique ID for each place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_place[df_place['name']=='Tampa']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the `woeid` of Tampa in tampa_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tampa_id = df_place[df_place['name']=='Tampa']['woeid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Return the trends in Tampa.\n",
    "\n",
    "Note: you need to convert the city_id from a pandas series object into an integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make Tampa as an example\n",
    "trends_tampa = api.get_place_trends(int(tampa_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the trends in JSON format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print the top 20 trends in Tampa\n",
    "trends_tampa[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organize the Tampa trends in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get trend name, URL, and tweet volume from the JSON data, and store them in a list\n",
    "trends_tampa_ls = [[trend['name'], trend['url'], trend['tweet_volume']] for trend in trends_tampa[0]['trends']]\n",
    "\n",
    "# Convert the list to a dataframe\n",
    "df_trends = pd.DataFrame(trends_tampa_ls,columns=['name','url','tweet_volume'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sort the trends by tweet volumn in a descending order and print the top 10 trends with the most tweeting volumne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sort the trends by tweet volumn in a descending order\n",
    "df_trends.sort_values(\"tweet_volume\", inplace = True, ascending = False)\n",
    "\n",
    "# Print the top 10 trends ranked by tweet volumne\n",
    "df_trends.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table shows the popular topics people are tweeting about in Tampa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Acquiring Tweets using the Search API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Search Tweets using Keywords\n",
    "\n",
    "In this step, you will use Python program to search tweets that contain a specific keyword. \n",
    "\n",
    "You can replace the key words to something you are interesting. Please try to choose a popular one so that you can collect sufficient tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets = api.search_tweets(\"Football\", count=100)\n",
    "\n",
    "print(\"Total retweet retrieved: \"+ str(len(tweets)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the user name, user location, posting time, and tweet text in a Pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_pd = pd.DataFrame([[tweet.user.name, tweet.user.location,tweet.created_at, tweet.text] for tweet in tweets], \n",
    "                         columns = ['user_name','user_loc','creation_time','text'])\n",
    "\n",
    "tweets_pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `search_tweets` funciton can retrieve max 100 tweets at a time. If you want to get more tweets, you need to use a `cursor`.\n",
    "\n",
    "The following code use a cursor to retrieve more tweets containing a keyword. Here we still retrieve 100 tweets to save your search quota for the following steps. You could increase the `num` variable if you want to get more tweets.\n",
    "\n",
    "> Note: Twitter only allows you to retrieve a limited number of tweets per 15 minutes. If the retrieved tweets exceed the limit, the program will pause for a certain amount time. If you can't wait, you can doublepress `i` on your keyboard to interrupt the process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of tweets to be retrieved.\n",
    "num = 100\n",
    "\n",
    "# define the search keyword\n",
    "keyword = \"Football\"\n",
    "\n",
    "# use cursor to send your request with parameters\n",
    "tweets = tweepy.Cursor(api.search_tweets,\n",
    "                   q = keyword,\n",
    "                   count = num,\n",
    "                   lang=\"en\").items(num)\n",
    "\n",
    "# restore the results as a list\n",
    "tweet_ls = [[tweet.user.name, tweet.user.location,tweet.created_at, tweet.text] for tweet in tweets]\n",
    "\n",
    "# Store the retrieved tweets in a dataframe\n",
    "tweets_pd_full = pd.DataFrame(tweet_ls, \n",
    "                         columns = ['user_name','user_loc','creation_time','text'])\n",
    "\n",
    "# Print the dataframe\n",
    "tweets_pd_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Filter out Retweets\n",
    "The retrieved tweets include both original tweets and retweets. The content of retweets are almost identical and carry little information. You can set up a filter to eliminate the retweets and keep only the original tweets.\n",
    "\n",
    "To filter out retweets, you can simply add `-filter:retweets` in the search keyword."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_keyword = \"Football\" + \" -filter:retweets\"\n",
    "new_keyword"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code retrieve only original tweets that contain the keyword \"Football\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets to be retrieved.\n",
    "num = 100\n",
    "\n",
    "# use cursor to send your request with parameters\n",
    "tweets = tweepy.Cursor(api.search_tweets,\n",
    "                   q = new_keyword,\n",
    "                   count = num,\n",
    "                   lang=\"en\").items(num)\n",
    "\n",
    "# restore the results as a list\n",
    "tweet_ls = [[tweet.user.name, tweet.user.location,tweet.created_at, tweet.text] for tweet in tweets]\n",
    "\n",
    "# Store the retrieved tweets in a dataframe\n",
    "tweets_pd_full = pd.DataFrame(tweet_ls, \n",
    "                         columns = ['user_name','user_loc','creation_time','text'])\n",
    "\n",
    "# Print the dataframe\n",
    "tweets_pd_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Search Tweets using locations\n",
    "\n",
    "You can also search for tweets around a certain location. The spatial query is based on geotags and/or user locations of the tweets.\n",
    "\n",
    "The following code will retrieve 200 tweets containing \"Football\" within a 20 mile radius from USF (28.0619,-82.4146)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Number of tweets to be retrieved.\n",
    "num = 200\n",
    "\n",
    "# define the search keyword\n",
    "keyword = \"Football\"\n",
    "\n",
    "# use cursor to send your request with parameters\n",
    "tweets = tweepy.Cursor(api.search_tweets,\n",
    "                   q=keyword,\n",
    "                   geocode = \"28.0619,-82.4146,20mi\",\n",
    "                   count = num,\n",
    "                   lang=\"en\").items(num)\n",
    "\n",
    "# restore the results as a list\n",
    "tweet_ls = [[tweet.user.name, tweet.user.location, tweet.place, tweet.created_at, tweet.text] for tweet in tweets]\n",
    "\n",
    "# Store the retrieved tweets in a dataframe\n",
    "tweets_pd_geo = pd.DataFrame(tweet_ls, \n",
    "                         columns = ['user_name','user_loc','geotag','creation_time','text'])\n",
    "\n",
    "# Print the dataframe\n",
    "tweets_pd_geo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to map the tweets using their geotags. However, only a very small proportion (1-2%) of tweets have a geotag. We first check how many of the 200 tweets have a  geotag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = len(tweets_pd_geo[tweets_pd_geo['geotag'].notna()]) # all retrieved tweets\n",
    "geo = len(tweets_pd_geo) # tweets that actually have geotags.\n",
    "\n",
    "print(\"%s out of the %s retrieved tweets actually have a geotag\" % (all, geo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Copy tweets with geotags to a new dataframe called \"geotags\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_tweets = tweets_pd_geo.loc[tweets_pd_geo['geotag'].notna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check detailed data in a geotag. The location of the geotag is in a bounding box defined by the four coordinate pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "geo_tweets.iloc[0].geotag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get coordinates of the bounding box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo_tweets.iloc[0].geotag.bounding_box.coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a column in the dataframe to store coordinates of the bounding boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store bounding box coordinates to a new column\n",
    "geo_tweets['bounding_box'] = geo_tweets.geotag.apply(lambda s:s.bounding_box.coordinates[0])\n",
    "\n",
    "# print the geotag\n",
    "geo_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For mapping purpose, we will simplify the bounding boxes to their centroids (points). In such a way, each tweet will be pinned to the centroid of the bounding box in the geotag.\n",
    "\n",
    "The following code calculate the lat, lon of centroids and store them in two new columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_tweets['point']  = geo_tweets['bounding_box'].apply(lambda s: [(s[0][1]+s[2][1])/2,(s[0][0]+s[2][0])/2])\n",
    "\n",
    "geo_tweets['lat']  = geo_tweets['bounding_box'].apply(lambda s: (s[0][1]+s[2][1])/2)\n",
    "\n",
    "geo_tweets['lon']  = geo_tweets['bounding_box'].apply(lambda s: (s[0][0]+s[2][0])/2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print to see the dataframe again. You'll see the centroids, latitude, and longitude are added as columns in the dataframe.\n",
    "\n",
    "Note: the point column is an redundancy of the lat and lon columns. We create all these columns just in case you want to convert the dataframe to a geodataframe (geometry)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Mapping Geotagged Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use folium to create an interactive map for the geotagged tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a base map\n",
    "maptweet = folium.Map()\n",
    "\n",
    "# Add the tweets into the basemap\n",
    "for i, row in geo_tweets.iterrows():\n",
    "    folium.Marker(row.point,popup = row.text).add_to(maptweet)\n",
    "    \n",
    "# Zoom to the bounding box including the tweets\n",
    "maptweet.fit_bounds([[min(geo_tweets.lat),min(geo_tweets.lon)],[max(geo_tweets.lat),max(geo_tweets.lon)]])\n",
    "\n",
    "# Show the map\n",
    "display(maptweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Streaming Tweets\n",
    "\n",
    "Unlike the Search API, the Streaming API utilizes Twitter's HTTP protocol to deliver data through an open, streaming API connection. A single streaming connection is opened between your app and the API, with new results being sent through that connection whenever new matches occur. This results in a low-latency delivery mechanism that can support very high throughput. For further information, see https://developer.twitter.com/en/docs/tutorials/consuming-streaming-data.\n",
    "\n",
    "Depending on the filter (the speed of retrieval), the streaming API is also subject to a limit per 15 minutes. If the retrieved tweets exceed the limit, your program will pause for the next 15 minutes cycle.\n",
    "\n",
    "Run the following code to start streaming. The text messages are printed. You can double press `I` to interrupt the streaming. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import csv\n",
    "\n",
    "# paste your API keys and tokens to replace ......\n",
    "API_key = '......'\n",
    "API_key_secret = '......'\n",
    "access_token = '......'\n",
    "access_token_secret = '......'\n",
    "\n",
    "auth = tweepy.OAuthHandler(API_key, API_key_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth, wait_on_rate_limit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the follow code to stream real-time tweets and save them in a CSV file in your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define path and name of output file\n",
    "output_file = \"tweets.csv\"\n",
    "\n",
    "# Open a file to write in streamed tweets\n",
    "with open(output_file, \"w\", encoding=\"utf-8\",newline='') as f:\n",
    "    writer = csv.writer(f)\n",
    "    \n",
    "    # Write the headers in the first row\n",
    "    writer.writerow([\"username\",\"created_at\", \"geotag\", \"user_location\", \"lang\",\"tweet\"])\n",
    "    \n",
    "    # Define a sub-object of tweepy.Stream\n",
    "    class stream_csv(tweepy.Stream):\n",
    "        def on_status(self, status):\n",
    "            # Skip retweets and collect only geotagged tweets\n",
    "            if (not status.retweeted) and ('RT @' not in status.text) and (status.place is not None):\n",
    "                # Organize attributes of a tweet in a list\n",
    "                line = [status.user.name, status.user.created_at, status.place.bounding_box.coordinates[0], status.user.location, status.lang, status.text]\n",
    "                print(line) # Print the line\n",
    "                writer.writerow(line) # write the line to csv file\n",
    "\n",
    "    streamer = stream_csv(API_key, API_key_secret, access_token, access_token_secret)\n",
    "    streamer.filter(languages=[\"en\"], track=[\"putin\"])\n",
    "    streamer.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can double press `I` to stop the streaming (there is no better way to do it...). Before starting a new streaming, you need to disconnect the streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "streamer.disconnect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
